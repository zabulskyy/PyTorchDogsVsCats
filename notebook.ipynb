{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch implementation for dogs vs cats classificator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path as osp\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data loader\n",
    "class Data:\n",
    "    def __init__(self, shape=(224, 224)):\n",
    "        # shape of the every image, 224x224 is a standart size for VGG \n",
    "        self.shape = shape\n",
    "        \n",
    "        self.train_dir = None\n",
    "        self.train_imgs = None\n",
    "        self.train_len = None\n",
    "        self.train_X = None\n",
    "        self.train_y = None\n",
    "        \n",
    "        self.test_dir = None\n",
    "        self.test_imgs = None\n",
    "        self.test_len = None\n",
    "        self.test_X = None\n",
    "\n",
    "    def load_train(self, path):\n",
    "        self.train_dir = path\n",
    "        self.train_imgs = os.listdir(path)\n",
    "        self.train_len = len(self.train_imgs)\n",
    "\n",
    "        X = torch.zeros((self.train_len, 3, 224, 224))\n",
    "        y = torch.zeros((self.train_len, 2))\n",
    "        tr = transforms.ToTensor()\n",
    "        \n",
    "        for i, cur_im_name in enumerate(self.train_imgs):\n",
    "            if (i % 1000 == 999):\n",
    "                print(\"%.1f percents of train data loaded\" % (i / self.train_len * 100))\n",
    "            im_path = osp.join(self.train_dir, cur_im_name)\n",
    "            im = Image.open(im_path)\n",
    "            assert im.size == self.shape\n",
    "            im = tr(im)\n",
    "            X[i, :] = im\n",
    "            if cur_im_name[:3] == \"cat\":\n",
    "                y[i, 0] = 0\n",
    "                y[i, 1] = 1\n",
    "            else:\n",
    "                y[i, 0] = 1\n",
    "                y[i, 1] = 0\n",
    "        self.train_X = X.float()\n",
    "        self.train_y = y.float()\n",
    "        return self.train_X, self.train_y\n",
    "\n",
    "    def load_test(self, path):\n",
    "        self.test_dir = path\n",
    "        self.test_imgs = sorted(os.listdir(path)[:],  key=lambda x: int(x[:-4])) # remove .jpg extension\n",
    "        self.test_len = len(self.test_imgs)\n",
    "\n",
    "        X = torch.zeros((len(self.test_imgs), 3, 224, 224))\n",
    "        tr = transforms.ToTensor()\n",
    "        \n",
    "        for i, cur_im_name in enumerate(self.test_imgs):\n",
    "            if (i % 100 == 0):\n",
    "                print(\"%.1f percents of test data loaded\" % (i / self.test_len * 100))\n",
    "            im_path = osp.join(self.test_dir, cur_im_name)\n",
    "            im = Image.open(im_path)\n",
    "            assert im.size == self.shape\n",
    "            im = tr(im)\n",
    "            X[i, :] = im\n",
    "        self.test_X = X.float()\n",
    "        return self.test_X\n",
    "\n",
    "# resize images before running the net\n",
    "def resize_and_save(folder_from, folder_to, shape=(224, 224)):\n",
    "    imgs = os.listdir(folder_from)\n",
    "    l = len(imgs)\n",
    "    for n, i in enumerate(imgs):\n",
    "        im = Image.open(os.path.join(folder_from, i)).resize(shape)\n",
    "        if (n % 100 == 0):\n",
    "            print(\"%.1f percents resized\" % (n / l * 100))\n",
    "        im.convert('RGB').save(os.path.join(folder_to, i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, X, y, optimizer, criterion, CUDA=False, epo=10, batch_size=20, save_model_to=None):\n",
    "    print(\"training...\")\n",
    "    for e in range(epo):\n",
    "        running_loss = 0\n",
    "        print(\"{} epoch: \".format(e))\n",
    "        for batch in range(0, int(X.shape[0] / batch_size)):\n",
    "            try:\n",
    "                batch_X = X[batch * batch_size:(batch + 1) * batch_size]\n",
    "                batch_y = y[batch * batch_size:(batch + 1) * batch_size]\n",
    "            except IndexError:\n",
    "                print(\"batch out of range\")\n",
    "                break\n",
    "            if CUDA:\n",
    "                batch_X, batch_y = batch_X.cuda(), batch_y.cuda()\n",
    "            optimizer.zero_grad()\n",
    "            y_pred = model(batch_X)\n",
    "            loss = criterion(y_pred, torch.max(batch_y, 1)[1])\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "            if (batch % 1000 == 999):\n",
    "                print(\"\\tbatch: {}/{}, loss: {}\".format(batch+1, int(X.shape[0] / batch_size), running_loss))\n",
    "                running_loss = 0\n",
    "\n",
    "    if save_model_to is not None:\n",
    "        torch.save(model, save_model_to)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(model, X, CUDA=False, res_filename=\"result.csv\"):\n",
    "    if CUDA:\n",
    "        X = X.cuda()\n",
    "    sm = torch.nn.Softmax(dim=1)\n",
    "    filename = res_filename\n",
    "\n",
    "    # test one by one\n",
    "    for batch in range(int(X.shape[0])):\n",
    "        batch_X = X[batch:batch + 1]\n",
    "        if CUDA:\n",
    "            batch_X = batch_X.cuda()\n",
    "        y_pred = sm(model(batch_X)).round().int().tolist()[0]\n",
    "        y = [str(batch+1), \"0\"] if y_pred == [0, 1] else [str(batch+1), \"1\"]\n",
    "        print(\",\".join(y), file=open(filename, \"a+\"))\n",
    "        if (batch % 1000 == 999):\n",
    "            print(\"batch: {}\".format(batch+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating a model...\n",
      "model created\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "CUDA = torch.cuda.is_available()\n",
    "\n",
    "# create a model\n",
    "print(\"creating a model...\")\n",
    "model = torchvision.models.vgg13_bn(num_classes=2)\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "if CUDA:\n",
    "    model = model.cuda()\n",
    "    criterion = criterion.cuda()\n",
    "print(\"model created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data...\n",
      "4.0 percents of train data loaded\n",
      "8.0 percents of train data loaded\n",
      "12.0 percents of train data loaded\n",
      "16.0 percents of train data loaded\n",
      "20.0 percents of train data loaded\n",
      "24.0 percents of train data loaded\n",
      "28.0 percents of train data loaded\n",
      "32.0 percents of train data loaded\n",
      "36.0 percents of train data loaded\n",
      "40.0 percents of train data loaded\n",
      "44.0 percents of train data loaded\n",
      "48.0 percents of train data loaded\n",
      "52.0 percents of train data loaded\n",
      "56.0 percents of train data loaded\n",
      "60.0 percents of train data loaded\n",
      "64.0 percents of train data loaded\n",
      "68.0 percents of train data loaded\n",
      "72.0 percents of train data loaded\n",
      "76.0 percents of train data loaded\n",
      "80.0 percents of train data loaded\n",
      "84.0 percents of train data loaded\n",
      "88.0 percents of train data loaded\n",
      "92.0 percents of train data loaded\n",
      "96.0 percents of train data loaded\n",
      "100.0 percents of train data loaded\n",
      "data loaded\n",
      "train size: 25000\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "print(\"loading data...\")\n",
    "DATA_PATH = \"data\"\n",
    "data = Data()\n",
    "X, y = data.load_train(osp.join(DATA_PATH, \"train\"))\n",
    "print(\"data loaded\")\n",
    "print(\"train size: {}\".format(data.train_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training...\n",
      "0 epoch: \n",
      "\tbatch: 1000/5000, loss: 1154.607865867205\n",
      "\tbatch: 2000/5000, loss: 704.5586712956429\n",
      "\tbatch: 3000/5000, loss: 694.5664251744747\n",
      "\tbatch: 4000/5000, loss: 692.1011261343956\n",
      "\tbatch: 5000/5000, loss: 677.0551397204399\n"
     ]
    }
   ],
   "source": [
    "model = train(model, X, y, optimizer, criterion, CUDA, epo = 1, batch_size = 5)\n",
    "# train(model, X, y, optimizer, criterion, CUDA=False, epo = 10, batch_size = 20, save_model_to=None\n",
    "data = Data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 percents of test data loaded\n",
      "0.8 percents of test data loaded\n",
      "1.6 percents of test data loaded\n",
      "2.4 percents of test data loaded\n",
      "3.2 percents of test data loaded\n",
      "4.0 percents of test data loaded\n",
      "4.8 percents of test data loaded\n",
      "5.6 percents of test data loaded\n",
      "6.4 percents of test data loaded\n",
      "7.2 percents of test data loaded\n",
      "8.0 percents of test data loaded\n",
      "8.8 percents of test data loaded\n",
      "9.6 percents of test data loaded\n",
      "10.4 percents of test data loaded\n",
      "11.2 percents of test data loaded\n",
      "12.0 percents of test data loaded\n",
      "12.8 percents of test data loaded\n",
      "13.6 percents of test data loaded\n",
      "14.4 percents of test data loaded\n",
      "15.2 percents of test data loaded\n",
      "16.0 percents of test data loaded\n",
      "16.8 percents of test data loaded\n",
      "17.6 percents of test data loaded\n",
      "18.4 percents of test data loaded\n",
      "19.2 percents of test data loaded\n",
      "20.0 percents of test data loaded\n",
      "20.8 percents of test data loaded\n",
      "21.6 percents of test data loaded\n",
      "22.4 percents of test data loaded\n",
      "23.2 percents of test data loaded\n",
      "24.0 percents of test data loaded\n",
      "24.8 percents of test data loaded\n",
      "25.6 percents of test data loaded\n",
      "26.4 percents of test data loaded\n",
      "27.2 percents of test data loaded\n",
      "28.0 percents of test data loaded\n",
      "28.8 percents of test data loaded\n",
      "29.6 percents of test data loaded\n",
      "30.4 percents of test data loaded\n",
      "31.2 percents of test data loaded\n",
      "32.0 percents of test data loaded\n",
      "32.8 percents of test data loaded\n",
      "33.6 percents of test data loaded\n",
      "34.4 percents of test data loaded\n",
      "35.2 percents of test data loaded\n",
      "36.0 percents of test data loaded\n",
      "36.8 percents of test data loaded\n",
      "37.6 percents of test data loaded\n",
      "38.4 percents of test data loaded\n",
      "39.2 percents of test data loaded\n",
      "40.0 percents of test data loaded\n",
      "40.8 percents of test data loaded\n",
      "41.6 percents of test data loaded\n",
      "42.4 percents of test data loaded\n",
      "43.2 percents of test data loaded\n",
      "44.0 percents of test data loaded\n",
      "44.8 percents of test data loaded\n",
      "45.6 percents of test data loaded\n",
      "46.4 percents of test data loaded\n",
      "47.2 percents of test data loaded\n",
      "48.0 percents of test data loaded\n",
      "48.8 percents of test data loaded\n",
      "49.6 percents of test data loaded\n",
      "50.4 percents of test data loaded\n",
      "51.2 percents of test data loaded\n",
      "52.0 percents of test data loaded\n",
      "52.8 percents of test data loaded\n",
      "53.6 percents of test data loaded\n",
      "54.4 percents of test data loaded\n",
      "55.2 percents of test data loaded\n",
      "56.0 percents of test data loaded\n",
      "56.8 percents of test data loaded\n",
      "57.6 percents of test data loaded\n",
      "58.4 percents of test data loaded\n",
      "59.2 percents of test data loaded\n",
      "60.0 percents of test data loaded\n",
      "60.8 percents of test data loaded\n",
      "61.6 percents of test data loaded\n",
      "62.4 percents of test data loaded\n",
      "63.2 percents of test data loaded\n",
      "64.0 percents of test data loaded\n",
      "64.8 percents of test data loaded\n",
      "65.6 percents of test data loaded\n",
      "66.4 percents of test data loaded\n",
      "67.2 percents of test data loaded\n",
      "68.0 percents of test data loaded\n",
      "68.8 percents of test data loaded\n",
      "69.6 percents of test data loaded\n",
      "70.4 percents of test data loaded\n",
      "71.2 percents of test data loaded\n",
      "72.0 percents of test data loaded\n",
      "72.8 percents of test data loaded\n",
      "73.6 percents of test data loaded\n",
      "74.4 percents of test data loaded\n",
      "75.2 percents of test data loaded\n",
      "76.0 percents of test data loaded\n",
      "76.8 percents of test data loaded\n",
      "77.6 percents of test data loaded\n",
      "78.4 percents of test data loaded\n",
      "79.2 percents of test data loaded\n",
      "80.0 percents of test data loaded\n",
      "80.8 percents of test data loaded\n",
      "81.6 percents of test data loaded\n",
      "82.4 percents of test data loaded\n",
      "83.2 percents of test data loaded\n",
      "84.0 percents of test data loaded\n",
      "84.8 percents of test data loaded\n",
      "85.6 percents of test data loaded\n",
      "86.4 percents of test data loaded\n",
      "87.2 percents of test data loaded\n",
      "88.0 percents of test data loaded\n",
      "88.8 percents of test data loaded\n",
      "89.6 percents of test data loaded\n",
      "90.4 percents of test data loaded\n",
      "91.2 percents of test data loaded\n",
      "92.0 percents of test data loaded\n",
      "92.8 percents of test data loaded\n",
      "93.6 percents of test data loaded\n",
      "94.4 percents of test data loaded\n",
      "95.2 percents of test data loaded\n",
      "96.0 percents of test data loaded\n",
      "96.8 percents of test data loaded\n",
      "97.6 percents of test data loaded\n",
      "98.4 percents of test data loaded\n",
      "99.2 percents of test data loaded\n",
      "batch: 1000\n",
      "batch: 2000\n",
      "batch: 3000\n",
      "batch: 4000\n",
      "batch: 5000\n",
      "batch: 6000\n",
      "batch: 7000\n",
      "batch: 8000\n",
      "batch: 9000\n",
      "batch: 10000\n",
      "batch: 11000\n",
      "batch: 12000\n"
     ]
    }
   ],
   "source": [
    "X = data.load_test(\"data/test1\")\n",
    "run(model, X, CUDA, \"results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
